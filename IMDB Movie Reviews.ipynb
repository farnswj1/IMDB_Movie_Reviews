{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Movie Reviews\n",
    "### Justin Farnsworth (farnswj1@tcnj.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-PUTV2BM:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>IMDB Movie Reviews</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e652112d60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"IMDB Movie Reviews\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset through Pandas (Spark loads the data incorrectly)\n",
    "df = pd.read_csv(\"IMDB_Dataset.zip\", compression=\"zip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              review|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|A wonderful littl...| positive|\n",
      "|I thought this wa...| positive|\n",
      "|Basically there's...| negative|\n",
      "|Petter Mattei's \"...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into Spark\n",
    "reviews = spark.createDataFrame(df)\n",
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of cases for each classification\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processor class (will be used in the upcoming Spark pipeline)\n",
    "class TextProcessor(Transformer):\n",
    "    # List of stopwords (without punctuation)\n",
    "    set_of_stopwords = {\n",
    "        ''.join(char for char in word if char not in string.punctuation) for word in stopwords.words(\"english\") + [\"br\"]\n",
    "    }\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, inputCol):\n",
    "        super(TextProcessor, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "    \n",
    "    \n",
    "    # Transformation function\n",
    "    def _transform(self, df):\n",
    "        f = udf(lambda x: self.process(x), StringType())\n",
    "        return df.withColumn(self.inputCol, f(self.inputCol))\n",
    "    \n",
    "    \n",
    "    # Remove punctuations and stopwords from the messsage\n",
    "    def process(self, text):\n",
    "        # Remove any punctuations\n",
    "        nopunc = ''.join(char for char in text if char not in string.punctuation).lower()\n",
    "        \n",
    "        # Remove any stopwords\n",
    "        return ' '.join(word for word in nopunc.split() if word.lower() not in self.set_of_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewers mentioned watching 1 oz episode ...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically theres family little boy jake thinks...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job creative original...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary schools n...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movies high art fans exp...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the text processor and clean the messages\n",
    "test_processor = TextProcessor(inputCol=\"review\")\n",
    "cleaned_text = df[\"review\"].apply(test_processor.process)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 83510),\n",
       " ('film', 74453),\n",
       " ('one', 51024),\n",
       " ('like', 38989),\n",
       " ('good', 28569),\n",
       " ('even', 24572),\n",
       " ('would', 24024),\n",
       " ('time', 23257),\n",
       " ('really', 22948),\n",
       " ('see', 22534),\n",
       " ('story', 22090),\n",
       " ('much', 18947),\n",
       " ('well', 18791),\n",
       " ('get', 18204),\n",
       " ('great', 17819),\n",
       " ('also', 17816),\n",
       " ('bad', 17704),\n",
       " ('people', 17538),\n",
       " ('first', 17154),\n",
       " ('movies', 15453),\n",
       " ('made', 15415),\n",
       " ('make', 15305),\n",
       " ('films', 15285),\n",
       " ('could', 15155),\n",
       " ('way', 15000),\n",
       " ('characters', 14676),\n",
       " ('think', 14215),\n",
       " ('watch', 13567),\n",
       " ('many', 13369),\n",
       " ('seen', 13055),\n",
       " ('two', 13019),\n",
       " ('character', 12920),\n",
       " ('never', 12874),\n",
       " ('love', 12570),\n",
       " ('acting', 12471),\n",
       " ('plot', 12365),\n",
       " ('little', 12328),\n",
       " ('best', 12324),\n",
       " ('know', 12267),\n",
       " ('show', 12029),\n",
       " ('life', 11684),\n",
       " ('ever', 11623),\n",
       " ('better', 11044),\n",
       " ('still', 10740),\n",
       " ('say', 10623),\n",
       " ('end', 10537),\n",
       " ('scene', 10527),\n",
       " ('man', 10291),\n",
       " ('scenes', 10177),\n",
       " ('something', 9802)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most common words across all of the reviews\n",
    "Counter(' '.join(cleaned_text).split()).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "train_set, test_set = reviews.randomSplit([0.8, 0.2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tokenizer and text vector\n",
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"tokens\")\n",
    "word_hash = HashingTF(inputCol=\"tokens\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use string indexing to convert the sentiment values into integers\n",
    "sentiment_indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes to predict the sentiments\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[test_processor, tokenizer, word_hash, sentiment_indexer, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = pipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make the predictions\n",
    "predictions = model.transform(test_set).select(col(\"label\"), col(\"prediction\"))\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547519426180514"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use an evaluator to measure the performance of the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4356,  645],\n",
       "       [ 813, 4224]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the confusion matrix\n",
    "predictions_pandas = predictions.toPandas()\n",
    "confusion_matrix(predictions_pandas[\"label\"], predictions_pandas[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
